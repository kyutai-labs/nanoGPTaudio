{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "\n",
    "def load_audio_file(file: Path | str) -> np.ndarray:\n",
    "    audio, sr = librosa.load(file, mono=True)\n",
    "    audio = librosa.resample(audio, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
    "    # audio_mu_law = (librosa.mu_compress(audio, mu=255) + 128).astype(np.uint8)\n",
    "    return audio\n",
    "\n",
    "\n",
    "example_audio = load_audio_file(\n",
    "    # \"/lustre/scwpod02/client/kyutai/datasets/librilight_segmented/train/4667/7513/historyofchurch_06_maccaffrey_64kb_0003.flac\"\n",
    "    \"/lustre/scwpod02/client/kyutai/vaclav/datasets/expresso/audio_48khz/conversational/ex01-ex02/default/ex01-ex02_default_010.wav\"\n",
    ")\n",
    "# :int(5.13 * SAMPLE_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "start_time = 101.5\n",
    "end_time = start_time + 7.5\n",
    "example_audio_trim = example_audio[\n",
    "    int(start_time * SAMPLE_RATE) : int(end_time * SAMPLE_RATE)\n",
    "]\n",
    "\n",
    "display(Audio(example_audio_trim, rate=SAMPLE_RATE))\n",
    "display(Audio(example_audio_trim, rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import audio_tokenizer_from_name\n",
    "\n",
    "\n",
    "def reconstruct_example(codec_name: str):\n",
    "    tokenizer = audio_tokenizer_from_name(codec_name, device=\"cpu\")\n",
    "    tokens = tokenizer.encode(example_audio_trim)\n",
    "    decoded = tokenizer.decode(tokens)\n",
    "\n",
    "    display(Audio(decoded, rate=SAMPLE_RATE))\n",
    "    display(Audio(decoded, rate=SAMPLE_RATE))\n",
    "    # return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_example(\"codec_0818_174920_4_rvq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_example(\"codec_0818_174908_8_rvq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_example(\"codec_0818_174912_16_rvq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_example(\"mimi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_example(\"mimi_8_rvq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array([2, 3, 4], dtype=np.int32) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "logits = torch.randn([5, 6, 7])\n",
    "targets = torch.randint(0, 7, size=[5, 6])\n",
    "weights_list = [100, 1, 1]\n",
    "\n",
    "weights = torch.Tensor(weights_list)\n",
    "weights = weights.repeat(logits.shape[1] // len(weights))[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from torch.nn import functional as F\n",
    "\n",
    "F.cross_entropy(\n",
    "    rearrange(logits, \"b t c -> b c t\"),\n",
    "    targets,\n",
    "    reduction=\"none\"\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "(logits * weights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = torch.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
